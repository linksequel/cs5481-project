{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2e496d8273ce08",
   "metadata": {},
   "source": "# UserCF、ItemCF、MX-SVD"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81d0e27d9e6ddb9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T16:44:50.460704Z",
     "start_time": "2025-04-12T16:44:50.454089Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "def load_dataset(path=\"./datas/hetrec2011-lastfm-2k\"):\n",
    "    # Load user-artist interactions\n",
    "    user_artists = pd.read_csv(f\"{path}/user_artists.dat\", sep='\\t')\n",
    "\n",
    "    # Load artists data\n",
    "    artists = pd.read_csv(f\"{path}/artists.dat\", sep='\\t')\n",
    "\n",
    "    return user_artists, artists\n",
    "\n",
    "# Preprocess data\n",
    "def preprocess_data(user_artists):\n",
    "    # Create user-item matrix\n",
    "    user_item_matrix_df = user_artists.pivot(index='userID', columns='artistID', values='weight').fillna(0)\n",
    "    return user_item_matrix_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e466510f1edb34",
   "metadata": {},
   "source": [
    "# userCF核心原理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5be1cbeb3c97888",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T16:44:50.469368Z",
     "start_time": "2025-04-12T16:44:50.465726Z"
    }
   },
   "outputs": [],
   "source": [
    "def user_based_cf(user_item_matrix_df, user_id, n_users=10, n_recommendations=10):\n",
    "    # Calculate user similarity\n",
    "    user_similarity = cosine_similarity(user_item_matrix_df)\n",
    "    user_similarity_df = pd.DataFrame(user_similarity, index=user_item_matrix_df.index, columns=user_item_matrix_df.index)\n",
    "\n",
    "    # Find similar users\n",
    "    similar_users = user_similarity_df[user_id].sort_values(ascending=False)[1:n_users+1].index\n",
    "\n",
    "    # Get recommendations\n",
    "    recommendations = defaultdict(float)\n",
    "\n",
    "    # 对于当前没听过的艺术家，以相似用户喜欢的艺术家频次为准,\n",
    "    # recommendations[item] = 累加（某user和其相似用户的相似度 * weight）\n",
    "    current_user_mean_weight = user_item_matrix_df.loc[user_id].mean()\n",
    "\n",
    "    for similar_user in similar_users:\n",
    "        similarity_between_user = user_similarity_df.loc[user_id, similar_user]\n",
    "        similar_user_mean_weight = user_item_matrix_df.loc[similar_user].mean()\n",
    "\n",
    "        for item in user_item_matrix_df.columns:\n",
    "            if user_item_matrix_df.loc[user_id, item] == 0 and user_item_matrix_df.loc[similar_user, item] > 0:\n",
    "                recommendations[item] += similarity_between_user * (user_item_matrix_df.loc[similar_user, item] - similar_user_mean_weight)\n",
    "\n",
    "    recommendations = {item: score + current_user_mean_weight for item, score in recommendations.items()}\n",
    "    # Sort recommendations\n",
    "    recommendations = sorted(recommendations.items(), key=lambda x: x[1], reverse=True)[:n_recommendations]\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde4afd1f794bbe7",
   "metadata": {},
   "source": [
    "# itemCf核心原理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d16f0572731c05a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-12T16:44:50.477960Z",
     "start_time": "2025-04-12T16:44:50.474999Z"
    }
   },
   "outputs": [],
   "source": [
    "def item_based_cf(user_item_matrix_df, user_id, n_items=10, n_recommendations=10):\n",
    "    # 1. Calculate item similarity between items\n",
    "    item_similarity = cosine_similarity(user_item_matrix_df.T)\n",
    "    item_similarity_df = pd.DataFrame(item_similarity, index=user_item_matrix_df.columns, columns=user_item_matrix_df.columns)\n",
    "\n",
    "    # 2. Get items the user has interacted with and weights > 0\n",
    "    user_related_items = user_item_matrix_df.loc[user_id]\n",
    "    related_items_id = user_related_items[user_related_items > 0].index.tolist()\n",
    "\n",
    "    # Get recommendations\n",
    "    recommendations = defaultdict(float)\n",
    "\n",
    "    for item_id in related_items_id:\n",
    "        item_weight = user_item_matrix_df.loc[user_id, item_id]\n",
    "\n",
    "        # 2.1 Find n top items similar to current item, according to item_similarity_df\n",
    "        similar_items = item_similarity_df[item_id].sort_values(ascending=False)[1:n_items+1]\n",
    "\n",
    "        for similar_item, similarity_between_item in similar_items.items():\n",
    "            # 2.2 only find the similar item is not in related_items_id, add it to recommendations\n",
    "            if similar_item in related_items_id:\n",
    "                continue\n",
    "            # the below similar_item's weight must be 0\n",
    "            recommendations[similar_item] += similarity_between_item * item_weight\n",
    "\n",
    "    # Sort recommendations\n",
    "    recommendations = sorted(recommendations.items(), key=lambda x: x[1], reverse=True)[:n_recommendations]\n",
    "    return recommendations"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T14:31:35.924455Z",
     "start_time": "2025-04-13T14:31:35.919844Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def is_sparse_matrix(df, threshold=0.1):\n",
    "    \"\"\"\n",
    "    判断一个DataFrame是否是稀疏矩阵\n",
    "\n",
    "    参数:\n",
    "    df (pd.DataFrame): 需要判断的DataFrame\n",
    "    threshold (float): 稀疏矩阵的阈值，非零元素比例低于该值则认为是稀疏矩阵\n",
    "\n",
    "    返回:\n",
    "    bool: 如果是稀疏矩阵返回True，否则返回False\n",
    "    \"\"\"\n",
    "    total_elements = df.size\n",
    "    non_zero_elements = df.astype(bool).sum().sum()\n",
    "    sparsity_ratio = non_zero_elements / total_elements\n",
    "    return sparsity_ratio"
   ],
   "id": "c83c4c6641d7ba0a",
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "id": "de99fc12a78344a1",
   "metadata": {},
   "source": [
    "# main运行"
   ]
  },
  {
   "cell_type": "code",
   "id": "ff5cd042bb86ad94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T14:31:42.563222Z",
     "start_time": "2025-04-13T14:31:37.118343Z"
    }
   },
   "source": [
    "def main():\n",
    "    # Load and preprocess data\n",
    "    user_artists, artists = load_dataset()\n",
    "    user_item_matrix_df = preprocess_data(user_artists)\n",
    "    print(\"是否是稀疏矩阵:\", is_sparse_matrix(user_item_matrix_df))\n",
    "    # Example: Get recommendations for a specific user\n",
    "    user_id = user_item_matrix_df.index[0]  # First user in the dataset\n",
    "    # user_id = int(input(\"input the user id:\"))\n",
    "\n",
    "    print(f\"User-based recommendations for user {user_id}:\")\n",
    "    user_recommendations = user_based_cf(user_item_matrix_df, user_id)\n",
    "    for item_id, score in user_recommendations:\n",
    "        artist_name = artists[artists['id'] == item_id]['name'].values[0] if item_id in artists['id'].values else \"Unknown\"\n",
    "        print(f\"Artist ID: {item_id}, Score: {score:.2f}, Name: {artist_name}\")\n",
    "\n",
    "    print(f\"\\nItem-based recommendations for user {user_id}:\")\n",
    "    item_recommendations = item_based_cf(user_item_matrix_df, user_id)\n",
    "    for item_id, score in item_recommendations:\n",
    "        artist_name = artists[artists['id'] == item_id]['name'].values[0] if item_id in artists['id'].values else \"Unknown\"\n",
    "        print(f\"Artist ID: {item_id}, Score: {score:.2f}, Name: {artist_name}\")\n",
    "\n",
    "main()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "是否是稀疏矩阵: 0.002782815119924182\n",
      "User-based recommendations for user 2:\n",
      "Artist ID: 511, Score: 11031.56, Name: U2\n",
      "Artist ID: 159, Score: 9437.26, Name: The Cure\n",
      "Artist ID: 1001, Score: 8636.79, Name: Pet Shop Boys\n",
      "Artist ID: 2562, Score: 6256.60, Name: Arcadia\n",
      "Artist ID: 1014, Score: 5248.06, Name: Erasure\n",
      "Artist ID: 993, Score: 5025.80, Name: Simple Minds\n",
      "Artist ID: 187, Score: 4850.40, Name: a-ha\n",
      "Artist ID: 4313, Score: 4472.78, Name: Nephew\n",
      "Artist ID: 227, Score: 3799.39, Name: The Beatles\n",
      "Artist ID: 6776, Score: 3573.63, Name: Book of Love\n",
      "\n",
      "Item-based recommendations for user 2:\n",
      "Artist ID: 2556, Score: 14102.14, Name: The Power Station\n",
      "Artist ID: 8995, Score: 13904.49, Name: Andy Taylor\n",
      "Artist ID: 1076, Score: 13796.74, Name: Wham!\n",
      "Artist ID: 2562, Score: 13181.35, Name: Arcadia\n",
      "Artist ID: 13161, Score: 12606.11, Name: Private\n",
      "Artist ID: 4313, Score: 12600.67, Name: Nephew\n",
      "Artist ID: 6350, Score: 12455.23, Name: TV-2\n",
      "Artist ID: 996, Score: 11801.53, Name: Mike & The Mechanics\n",
      "Artist ID: 4042, Score: 6047.56, Name: Damn Arms\n",
      "Artist ID: 4023, Score: 6047.56, Name: DJ Risk One\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Long program",
   "id": "805dbc2a41efcd41"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T18:51:50.151275Z",
     "start_time": "2025-04-13T15:52:40.641121Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the dataset\n",
    "def load_dataset(path=\"./datas/hetrec2011-lastfm-2k\"):\n",
    "    # Load user-artist interactions\n",
    "    user_artists = pd.read_csv(f\"{path}/user_artists.dat\", sep='\\t')\n",
    "\n",
    "    # Load artists data\n",
    "    artists = pd.read_csv(f\"{path}/artists.dat\", sep='\\t')\n",
    "\n",
    "    return user_artists, artists\n",
    "\n",
    "# Preprocess data\n",
    "def preprocess_data(user_artists):\n",
    "    # Create user-item matrix\n",
    "    user_item_matrix_df = user_artists.pivot(index='userID', columns='artistID', values='weight').fillna(0)\n",
    "    return user_item_matrix_df\n",
    "\n",
    "# User-based collaborative filtering\n",
    "# 根据与user_id的相似用户，推荐n个item（artist）给它\n",
    "def user_based_cf(user_item_matrix_df, user_id, n_users=10, n_recommendations=10):\n",
    "    # Calculate user similarity\n",
    "    user_similarity = cosine_similarity(user_item_matrix_df)\n",
    "    user_similarity_df = pd.DataFrame(user_similarity, index=user_item_matrix_df.index, columns=user_item_matrix_df.index)\n",
    "\n",
    "    # Find similar users\n",
    "    similar_users = user_similarity_df[user_id].sort_values(ascending=False)[1:n_users+1].index\n",
    "\n",
    "    # Get recommendations\n",
    "    recommendations = defaultdict(float)\n",
    "\n",
    "    # 对于当前没听过的艺术家，以相似用户喜欢的艺术家频次为准,\n",
    "    # recommendations[item] = 累加（某user和其相似用户的相似度 * weight）\n",
    "    for similar_user in similar_users:\n",
    "        similarity_between_user = user_similarity_df.loc[user_id, similar_user]\n",
    "\n",
    "        for item in user_item_matrix_df.columns:\n",
    "            if user_item_matrix_df.loc[user_id, item] == 0 and user_item_matrix_df.loc[similar_user, item] > 0:\n",
    "                recommendations[item] += similarity_between_user * user_item_matrix_df.loc[similar_user, item]\n",
    "\n",
    "    # Sort recommendations\n",
    "    recommendations = sorted(recommendations.items(), key=lambda x: x[1], reverse=True)[:n_recommendations]\n",
    "    return recommendations\n",
    "\n",
    "# Item-based collaborative filtering\n",
    "def item_based_cf(user_item_matrix_df, user_id, n_items=10, n_recommendations=10):\n",
    "    # 1. Calculate item similarity between items\n",
    "    item_similarity = cosine_similarity(user_item_matrix_df.T)\n",
    "    item_similarity_df = pd.DataFrame(item_similarity, index=user_item_matrix_df.columns, columns=user_item_matrix_df.columns)\n",
    "\n",
    "    # 2. Get items the user has interacted with and weights > 0\n",
    "    user_related_items = user_item_matrix_df.loc[user_id]\n",
    "    related_items_id = user_related_items[user_related_items > 0].index.tolist()\n",
    "\n",
    "    # Get recommendations\n",
    "    recommendations = defaultdict(float)\n",
    "\n",
    "    for item_id in related_items_id:\n",
    "        item_weight = user_item_matrix_df.loc[user_id, item_id]\n",
    "\n",
    "        # 2.1 Find n top items similar to current item, according to item_similarity_df\n",
    "        similar_items = item_similarity_df[item_id].sort_values(ascending=False)[1:n_items+1]\n",
    "\n",
    "        for similar_item, similarity_between_item in similar_items.items():\n",
    "            # 2.2 only find the similar item is not in related_items_id, add it to recommendations\n",
    "            if similar_item in related_items_id:\n",
    "                continue\n",
    "            # the below similar_item's weight must be 0\n",
    "            recommendations[similar_item] += similarity_between_item * item_weight\n",
    "\n",
    "    # Sort recommendations\n",
    "    recommendations = sorted(recommendations.items(), key=lambda x: x[1], reverse=True)[:n_recommendations]\n",
    "    return recommendations\n",
    "\n",
    "# Evaluate recommendations\n",
    "def evaluate(user_item_matrix, test_ratio=0.1, n_users=10, n_items=10, n_recommendations=10):\n",
    "    # Create a copy of the matrix to avoid modifying the original\n",
    "    matrix = user_item_matrix.copy()\n",
    "\n",
    "    # Metrics storage\n",
    "    metrics = {\n",
    "        'user_hr': [], 'user_ndcg': [], 'user_mrr': [],\n",
    "        'item_hr': [], 'item_ndcg': [], 'item_mrr': []\n",
    "    }\n",
    "\n",
    "    # Add progress bar\n",
    "    total_users = len(matrix.index)\n",
    "    print(f\"Evaluating recommendations for {total_users} users...\")\n",
    "\n",
    "    # For each user, hide some interactions as test data\n",
    "    for user_id in tqdm(matrix.index, desc=\"Evaluating\", ncols=80):\n",
    "        # Get items this user has interacted with\n",
    "        user_items = matrix.columns[matrix.loc[user_id] > 0].tolist()\n",
    "\n",
    "        # Skip users with too few interactions\n",
    "        if len(user_items) <= 2:\n",
    "            continue\n",
    "\n",
    "        # Randomly select items for testing\n",
    "        n_test = max(1, int(len(user_items) * test_ratio))\n",
    "        test_items = random.sample(user_items, n_test)\n",
    "\n",
    "        # Create training matrix by setting test items to zero\n",
    "        train_matrix = matrix.copy()\n",
    "        for item in test_items:\n",
    "            train_matrix.loc[user_id, item] = 0\n",
    "\n",
    "        # Get recommendations from both methods\n",
    "        user_recs = user_based_cf(train_matrix, user_id, n_users, n_recommendations)\n",
    "        item_recs = item_based_cf(train_matrix, user_id, n_items, n_recommendations)\n",
    "\n",
    "        # Extract just the item IDs\n",
    "        user_rec_items = [item_id for item_id, _ in user_recs]\n",
    "        item_rec_items = [item_id for item_id, _ in item_recs]\n",
    "\n",
    "        # Calculate metrics for user-based CF\n",
    "        metrics['user_hr'].append(hit_ratio(user_rec_items, test_items))\n",
    "        metrics['user_ndcg'].append(ndcg(user_rec_items, test_items))\n",
    "        metrics['user_mrr'].append(mrr(user_rec_items, test_items))\n",
    "\n",
    "        # Calculate metrics for item-based CF\n",
    "        metrics['item_hr'].append(hit_ratio(item_rec_items, test_items))\n",
    "        metrics['item_ndcg'].append(ndcg(item_rec_items, test_items))\n",
    "        metrics['item_mrr'].append(mrr(item_rec_items, test_items))\n",
    "        # print(metrics)\n",
    "\n",
    "    # Calculate average metrics\n",
    "    avg_metrics = {k: np.mean(v) for k, v in metrics.items() if v}\n",
    "\n",
    "    return avg_metrics\n",
    "\n",
    "# Hit Ratio@K\n",
    "def hit_ratio(recommended_items, test_items):\n",
    "    hits = len(set(recommended_items) & set(test_items))\n",
    "    return hits / len(test_items) if test_items else 0\n",
    "\n",
    "# NDCG@K\n",
    "def ndcg(recommended_items, test_items):\n",
    "    dcg = 0\n",
    "    idcg = 0\n",
    "\n",
    "    # Calculate DCG\n",
    "    for i, item in enumerate(recommended_items):\n",
    "        if item in test_items:\n",
    "            # Using binary relevance (1 if hit, 0 if miss)\n",
    "            dcg += 1 / np.log2(i + 2)  # i+2 because i starts from 0\n",
    "\n",
    "    # Calculate IDCG (ideal DCG - items are perfectly ranked)\n",
    "    for i in range(min(len(test_items), len(recommended_items))):\n",
    "        idcg += 1 / np.log2(i + 2)\n",
    "\n",
    "    return dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "# MRR@K\n",
    "def mrr(recommended_items, test_items):\n",
    "    for i, item in enumerate(recommended_items):\n",
    "        if item in test_items:\n",
    "            return 1 / (i + 1)  # i+1 because i starts from 0\n",
    "    return 0\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Load and preprocess data\n",
    "    user_artists, artists = load_dataset()\n",
    "    user_item_matrix_df = preprocess_data(user_artists)\n",
    "\n",
    "    # Example: Get recommendations for a specific user\n",
    "    user_id = user_item_matrix_df.index[0]  # First user in the dataset\n",
    "    # user_id = int(input(\"input the user id:\"))\n",
    "\n",
    "    print(f\"User-based recommendations for user {user_id}:\")\n",
    "    user_recommendations = user_based_cf(user_item_matrix_df, user_id)\n",
    "    for item_id, score in user_recommendations:\n",
    "        artist_name = artists[artists['id'] == item_id]['name'].values[0] if item_id in artists['id'].values else \"Unknown\"\n",
    "        print(f\"Artist ID: {item_id}, Score: {score:.2f}, Name: {artist_name}\")\n",
    "\n",
    "    print(f\"\\nItem-based recommendations for user {user_id}:\")\n",
    "    item_recommendations = item_based_cf(user_item_matrix_df, user_id)\n",
    "    for item_id, score in item_recommendations:\n",
    "        artist_name = artists[artists['id'] == item_id]['name'].values[0] if item_id in artists['id'].values else \"Unknown\"\n",
    "        print(f\"Artist ID: {item_id}, Score: {score:.2f}, Name: {artist_name}\")\n",
    "\n",
    "    # Evaluate the models\n",
    "    metrics = evaluate(user_item_matrix_df)\n",
    "    print(f\"\\nEvaluation results:\")\n",
    "    print(f\"User-based CF - HR@K: {metrics['user_hr']:.4f}, NDCG@K: {metrics['user_ndcg']:.4f}, MRR@K: {metrics['user_mrr']:.4f}\")\n",
    "    print(f\"Item-based CF - HR@K: {metrics['item_hr']:.4f}, NDCG@K: {metrics['item_ndcg']:.4f}, MRR@K: {metrics['item_mrr']:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "feabc998f9895706",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-based recommendations for user 2:\n",
      "Artist ID: 511, Score: 11033.60, Name: U2\n",
      "Artist ID: 159, Score: 9444.82, Name: The Cure\n",
      "Artist ID: 1001, Score: 8645.83, Name: Pet Shop Boys\n",
      "Artist ID: 2562, Score: 6262.49, Name: Arcadia\n",
      "Artist ID: 1014, Score: 5252.81, Name: Erasure\n",
      "Artist ID: 993, Score: 5032.88, Name: Simple Minds\n",
      "Artist ID: 187, Score: 4859.54, Name: a-ha\n",
      "Artist ID: 4313, Score: 4470.64, Name: Nephew\n",
      "Artist ID: 227, Score: 3800.56, Name: The Beatles\n",
      "Artist ID: 6776, Score: 3569.32, Name: Book of Love\n",
      "\n",
      "Item-based recommendations for user 2:\n",
      "Artist ID: 2556, Score: 14102.14, Name: The Power Station\n",
      "Artist ID: 8995, Score: 13904.49, Name: Andy Taylor\n",
      "Artist ID: 1076, Score: 13796.74, Name: Wham!\n",
      "Artist ID: 2562, Score: 13181.35, Name: Arcadia\n",
      "Artist ID: 13161, Score: 12606.11, Name: Private\n",
      "Artist ID: 4313, Score: 12600.67, Name: Nephew\n",
      "Artist ID: 6350, Score: 12455.23, Name: TV-2\n",
      "Artist ID: 996, Score: 11801.53, Name: Mike & The Mechanics\n",
      "Artist ID: 4042, Score: 6047.56, Name: Damn Arms\n",
      "Artist ID: 4023, Score: 6047.56, Name: DJ Risk One\n",
      "Evaluating recommendations for 1892 users...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|█████████████████████████| 1892/1892 [2:59:03<00:00,  5.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation results:\n",
      "User-based CF - HR@K: 0.1279, NDCG@K: 0.1162, MRR@K: 0.2138\n",
      "Item-based CF - HR@K: 0.0174, NDCG@K: 0.0159, MRR@K: 0.0337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 53
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
